{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os, os.path\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# supress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"pandas\", lineno=570)\n",
    "\n",
    "# custom tokenizer with stemmer \n",
    "class PorterTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.pt = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.pt.stem(t) for t in RegexpTokenizer(r'(?u)\\b\\w\\w+\\b').tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# process generated files\n",
    "abs_path = r'/home/yurii/projects/mownit2/lab6/outl/AB/'\n",
    "cur_path = r'/home/yurii/projects/mownit2/lab6/a/'\n",
    "for filename in os.listdir(abs_path):\n",
    "    with open(abs_path + filename, 'r') as myfile:\n",
    "        s = myfile.read()\n",
    "        p = re.compile('<doc[^>]*>([^<]*)<\\/doc>')\n",
    "        l = p.findall(s)\n",
    "        for i in range(0,len(l)):\n",
    "            p = re.compile('Notes\\n|Footnotes\\n|Bibliography\\n|References\\n|External links\\n|Further reading\\n')\n",
    "            l[i] = p.sub(r'', l[i])\n",
    "            p = re.compile('\\n{3,}')\n",
    "            l[i] = p.sub(r'\\n', l[i])\n",
    "            if l[i][0] == '\\n':\n",
    "                l[i] = l[i][1:]\n",
    "            title = l[i].splitlines()[0]\n",
    "            title = title.replace(r'/', ' ')\n",
    "            with open(cur_path + title, 'w+') as myfile2:\n",
    "                myfile2.write(l[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read each file into separate string\n",
    "art_path = r'/home/yurii/projects/mownit2/lab6/ex2/'\n",
    "file_list = [name for name in os.listdir(art_path)]\n",
    "doc_list = []\n",
    "for file in file_list:\n",
    "    with open(art_path + file, 'r') as myfile:\n",
    "        doc_list.append(myfile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vectorize strings using tf-idf vectorizer\n",
    "tfidf_matrix = TfidfVectorizer(min_df=1, stop_words='english', tokenizer=PorterTokenizer(), smooth_idf=False)\n",
    "tfidf_trans_matrix = tfidf_matrix.fit_transform(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt = pd.DataFrame(tfidf_trans_matrix.toarray(), index=file_list, columns=tfidf_trans_matrix.get_feature_names()).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_str = [\"blood guts beer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yurii/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1067: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(float(n_samples) / df) + 1.0\n"
     ]
    }
   ],
   "source": [
    "tfidf_search_matrix = TfidfVectorizer(vocabulary=tfidf_matrix.vocabulary_, stop_words='english', tokenizer=PorterTokenizer())\n",
    "tfidf_trans_smatrix = tfidf_search_matrix.fit_transform(search_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix = cosine_similarity(tfidf_trans_matrix[0], tfidf_trans_smatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.00876051,  0.00876051]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_trans_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.57735027  0.57735027  0.57735027]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_trans_smatrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.05763932  0.03749549  0.15858565  0.11978858  0.02675291\n",
      "   0.0907006   0.11164189]\n",
      " [ 0.05763932  1.          0.03148289  0.08993957  0.08264327  0.02422493\n",
      "   0.06884484  0.07784266]\n",
      " [ 0.03749549  0.03148289  1.          0.04795767  0.06178963  0.49599109\n",
      "   0.05040216  0.08425274]\n",
      " [ 0.15858565  0.08993957  0.04795767  1.          0.50723506  0.03950431\n",
      "   0.19850558  0.17649297]\n",
      " [ 0.11978858  0.08264327  0.06178963  0.50723506  1.          0.03595162\n",
      "   0.16197324  0.16648425]\n",
      " [ 0.02675291  0.02422493  0.49599109  0.03950431  0.03595162  1.\n",
      "   0.04547475  0.04851268]\n",
      " [ 0.0907006   0.06884484  0.05040216  0.19850558  0.16197324  0.04547475\n",
      "   1.          0.17426942]\n",
      " [ 0.11164189  0.07784266  0.08425274  0.17649297  0.16648425  0.04851268\n",
      "   0.17426942  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "sim_matrix = cosine_similarity(tfidf_trans_vect)\n",
    "print(sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_trans_vect.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector = CountVectorizer(min_df=1, stop_words='english', tokenizer=PorterTokenizer())\n",
    "# trans_vect = vector.fit_transform(doc_list)\n",
    "# dt = pd.DataFrame(trans_vect.toarray(), index=file_list, columns=vector.get_feature_names()).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# example = [\n",
    "#     'In mathematics, 1 − 2 + 3 − 4 + ··· is the infinite series whose terms are the successive positive integers, given alternating signs. Using sigma summation notation the sum of the first \"m\" terms of the series can be expressed as',\n",
    "#     'The infinite series diverges, meaning that its sequence of partial sums, , does not tend towards any finite limit. Nonetheless, in the mid-18th century, Leonhard Euler wrote what he admitted to be a paradoxical equation:',\n",
    "#     \"A rigorous explanation of this equation would not arrive until much later. Starting in 1890, Ernesto Cesàro, Émile Borel and others investigated well-defined methods to assign generalized sums to divergent series—including new interpretations of Euler's attempts.\"\n",
    "# ]\n",
    "\n",
    "# vect1 = CountVectorizer(min_df=1, stop_words='english', tokenizer=PorterTokenizer())\n",
    "# # vect2 = CountVectorizer(min_df=1, stop_words='english')\n",
    "# dtm1 = vect1.fit_transform(example)\n",
    "# # dtm2 = vect2.fit_transform(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(dtm1.toarray(), index=example, columns=vect1.get_feature_names()).head(10)\n",
    "# vect1.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(dtm2.toarray(), index=example, columns=vect2.get_feature_names()).head(10)\n",
    "# vect2.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dict_list = [col.OrderedDict([]) for i in range(0,len(file_list))]\n",
    "\n",
    "# def read_words(words_file):\n",
    "#     return [word for line in open(words_file, 'r') for word in line.split()]\n",
    "\n",
    "# file_name = art_path + r'0'\n",
    "# wl = read_words(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
